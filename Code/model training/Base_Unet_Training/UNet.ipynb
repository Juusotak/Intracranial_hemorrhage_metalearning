{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b63fb7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n",
      "zsh:1: command not found: nvidia-smi\n",
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "import cv2\n",
    "import glob\n",
    "from focal_loss import BinaryFocalLoss\n",
    "from tensorflow.keras.losses import BinaryFocalCrossentropy\n",
    "\n",
    "print(tf.__version__)\n",
    "tf.test.gpu_device_name()\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "print(gpu_info)\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7585ed44",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dropout = 0.1\n",
    "\n",
    "f1 = 10\n",
    "f2 = 20\n",
    "f3 = 40\n",
    "f4 = 80\n",
    "f5 = 160\n",
    "f6 = 320\n",
    "\n",
    "HU_min = -500.\n",
    "HU_max = 500.\n",
    "\n",
    "HU_min2 = 0.\n",
    "HU_max2 = 200.\n",
    "\n",
    "# Normalization for ICH and SAH models\n",
    "def normalize(image):\n",
    "    image = (image - HU_min) / (HU_max - HU_min)\n",
    "    image[image>1] = 1.\n",
    "    image[image<0] = 0.\n",
    "    return image\n",
    "\n",
    "# Normalization for IVH model\n",
    "def normalize2(image):\n",
    "    image = (image - HU_min2) / (HU_max2 - HU_min2)\n",
    "    image[image>1] = 1.\n",
    "    image[image<0] = 0.\n",
    "    return image\n",
    "\n",
    "\n",
    "smooth = 0.01\n",
    "alpha = 0.25\n",
    "gamma = 2.0\n",
    "\n",
    "def dice_coeff(y_true, y_pred):\n",
    "    y_true_f = tf.reshape(y_true, [-1])\n",
    "    y_pred_f = tf.reshape(y_pred, [-1])\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "    score = (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n",
    "    return score\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1 - dice_coeff(y_true, y_pred)\n",
    "\n",
    "focal_loss = BinaryFocalCrossentropy(alpha=alpha, gamma=gamma)\n",
    "\n",
    "def combined_loss(y_true, y_pred):\n",
    "    dice = dice_loss(y_true, y_pred)\n",
    "    focal = focal_loss(y_true, y_pred)\n",
    "    return dice + focal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8a4de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_model():\n",
    "    inputs = tf.keras.layers.Input(shape = (512,512,1))\n",
    "    c1 = tf.keras.layers.BatchNormalization()(inputs)\n",
    "\n",
    "    #Contraction path\n",
    "\n",
    "    c1 = tf.keras.layers.Conv2D(f1, (3,3), activation='relu',  padding='same')(c1)\n",
    "    d1 = tf.keras.layers.Dropout(Dropout)(c1)\n",
    "    r1 = tf.keras.layers.Conv2D(f1, (3,3), activation='relu',  padding='same')(d1)\n",
    "    r1 = tf.keras.layers.Conv2D(f1, (3,3), activation='relu',  padding='same')(r1)\n",
    "    r1 = tf.keras.layers.add([r1, c1])\n",
    "    r1 = tf.keras.layers.Conv2D(f1, (3,3), activation='relu',  padding='same')(r1)\n",
    "\n",
    "    p1 = tf.keras.layers.Conv2D(f1, (3,3), activation='relu',  padding='same',strides = (2,2))(r1)\n",
    "    p1 = tf.keras.layers.BatchNormalization()(p1)\n",
    "\n",
    "    c2 = tf.keras.layers.Conv2D(f2, (3,3), activation='relu',  padding='same')(p1)\n",
    "    d2 = tf.keras.layers.Dropout(Dropout)(c2)\n",
    "    r2 = tf.keras.layers.Conv2D(f2, (3,3), activation='relu',  padding='same')(d2)\n",
    "    r2 = tf.keras.layers.Conv2D(f2, (3,3), activation='relu',  padding='same')(r2)\n",
    "    r2 = tf.keras.layers.add([r2,c2])\n",
    "    r2 = tf.keras.layers.Conv2D(f2, (3,3), activation='relu',  padding='same')(r2)\n",
    "\n",
    "\n",
    "    p2 = tf.keras.layers.Conv2D(f2, (3,3), activation='relu',  padding='same',strides = (2,2))(r2)\n",
    "    p2 = tf.keras.layers.BatchNormalization()(p2)\n",
    "\n",
    "    c3 = tf.keras.layers.Conv2D(f3, (3,3), activation='relu',  padding='same')(p2)\n",
    "    d3 = tf.keras.layers.Dropout(Dropout)(c3)\n",
    "    r3 = tf.keras.layers.Conv2D(f3, (3,3), activation='relu',  padding='same')(d3)\n",
    "    r3 = tf.keras.layers.Conv2D(f3, (3,3), activation='relu',  padding='same')(r3)\n",
    "    r3 = tf.keras.layers.add([r3,c3])\n",
    "    r3 = tf.keras.layers.Conv2D(f3, (3,3), activation='relu',  padding='same')(r3)\n",
    "\n",
    "    p3 = tf.keras.layers.Conv2D(f3, (3,3), activation='relu',  padding='same',strides = (2,2))(r3)\n",
    "    p3 = tf.keras.layers.BatchNormalization()(p3)\n",
    "\n",
    "    c4 = tf.keras.layers.Conv2D(f4, (3,3), activation='relu',  padding='same')(p3)\n",
    "    d4 = tf.keras.layers.Dropout(Dropout)(c4)\n",
    "    r4 = tf.keras.layers.Conv2D(f4, (3,3), activation='relu',  padding='same')(d4)\n",
    "    r4 = tf.keras.layers.Conv2D(f4, (3,3), activation='relu',  padding='same')(r4)\n",
    "    r4 = tf.keras.layers.add([r4,c4])\n",
    "    r4 = tf.keras.layers.Conv2D(f4, (3,3), activation='relu',  padding='same')(r4)\n",
    "\n",
    "    p4 = tf.keras.layers.Conv2D(f4, (3,3), activation='relu',  padding='same',strides = (2,2))(r4)\n",
    "    p4 = tf.keras.layers.BatchNormalization()(p4)\n",
    "\n",
    "    c5 = tf.keras.layers.Conv2D(f5, (3,3), activation='relu',  padding='same')(p4)\n",
    "    d5 = tf.keras.layers.Dropout(Dropout)(c5)\n",
    "    r5 = tf.keras.layers.Conv2D(f5, (3,3), activation='relu',  padding='same')(d5)\n",
    "    r5 = tf.keras.layers.Conv2D(f5, (3,3), activation='relu',  padding='same')(r5)\n",
    "    r5 = tf.keras.layers.add([r5,c5])\n",
    "    r5 = tf.keras.layers.Conv2D(f5, (3,3), activation='relu',  padding='same')(r5)\n",
    "\n",
    "    p5 = tf.keras.layers.Conv2D(f5, (3,3), activation='relu',  padding='same',strides = (2,2))(r5)\n",
    "    p5 = tf.keras.layers.BatchNormalization()(p5)\n",
    "\n",
    "    c6 = tf.keras.layers.Conv2D(f6, (3,3), activation='relu',  padding='same')(p5)\n",
    "    d6 = tf.keras.layers.Dropout(Dropout)(c6)\n",
    "    r6 = tf.keras.layers.Conv2D(f6, (3,3), activation='relu',  padding='same')(d6)\n",
    "    r6 = tf.keras.layers.Conv2D(f6, (3,3), activation='relu',  padding='same')(r6)\n",
    "    r6 = tf.keras.layers.add([r6,c6])\n",
    "    r6 = tf.keras.layers.Conv2D(f6, (3,3), activation='relu',  padding='same')(r6)\n",
    "    \n",
    "    u11 = tf.keras.layers.Conv2DTranspose(f5, (2,2), activation='relu', strides = (2,2), padding = 'same')(r6)\n",
    "    u11 = tf.keras.layers.concatenate([u11, r5])\n",
    "    u11 = tf.keras.layers.BatchNormalization()(u11)\n",
    "\n",
    "    c11 = tf.keras.layers.Conv2D(f5, (3,3), activation='relu',  padding='same')(u11)\n",
    "    d11 = tf.keras.layers.Dropout(Dropout)(c11)\n",
    "    r11 = tf.keras.layers.Conv2D(f5, (3,3), activation='relu',  padding='same')(d11)\n",
    "    r11 = tf.keras.layers.Conv2D(f5, (3,3), activation='relu',  padding='same')(r11)\n",
    "    r11 = tf.keras.layers.add([r11,c11])\n",
    "    r11 = tf.keras.layers.Conv2D(f5, (3,3), activation='relu',  padding='same')(r11)\n",
    "\n",
    "    u12 = tf.keras.layers.Conv2DTranspose(f4, (2,2), activation='relu', strides = (2,2), padding = 'same')(r11)\n",
    "    u12 = tf.keras.layers.concatenate([u12, r4])\n",
    "    u12 = tf.keras.layers.BatchNormalization()(u12)\n",
    "\n",
    "    c12 = tf.keras.layers.Conv2D(f4, (3,3), activation='relu',  padding='same')(u12)\n",
    "    d12 = tf.keras.layers.Dropout(Dropout)(c12)\n",
    "    r12 = tf.keras.layers.Conv2D(f4, (3,3), activation='relu',  padding='same')(d12)\n",
    "    r12 = tf.keras.layers.Conv2D(f4, (3,3), activation='relu',  padding='same')(r12)\n",
    "    r12 = tf.keras.layers.add([r12,c12])\n",
    "    r12 = tf.keras.layers.Conv2D(f4, (3,3), activation='relu',  padding='same')(r12)\n",
    "\n",
    "    u13 = tf.keras.layers.Conv2DTranspose(f3, (2,2), activation='relu', strides = (2,2), padding = 'same')(r12)\n",
    "    u13 = tf.keras.layers.concatenate([u13, r3])\n",
    "    u13 = tf.keras.layers.BatchNormalization()(u13)\n",
    "\n",
    "    c13 = tf.keras.layers.Conv2D(f3, (3,3), activation='relu',  padding='same')(u13)\n",
    "    d13 = tf.keras.layers.Dropout(Dropout)(c13)\n",
    "    r13 = tf.keras.layers.Conv2D(f3, (3,3), activation='relu',  padding='same')(d13)\n",
    "    r13 = tf.keras.layers.Conv2D(f3, (3,3), activation='relu',  padding='same')(r13)\n",
    "    r13 = tf.keras.layers.add([r13,c13])\n",
    "    r13 = tf.keras.layers.Conv2D(f3, (3,3), activation='relu',  padding='same')(r13)\n",
    "\n",
    "    u14 = tf.keras.layers.Conv2DTranspose(f2, (2,2), activation='relu', strides = (2,2), padding = 'same')(r13)\n",
    "    u14 = tf.keras.layers.concatenate([u14, r2])\n",
    "    u14 = tf.keras.layers.BatchNormalization()(u14)\n",
    "\n",
    "    c14 = tf.keras.layers.Conv2D(f2, (3,3), activation='relu',  padding='same')(u14)\n",
    "    d14 = tf.keras.layers.Dropout(Dropout)(c14)\n",
    "    r14 = tf.keras.layers.Conv2D(f2, (3,3), activation='relu',  padding='same')(d14)\n",
    "    r14 = tf.keras.layers.Conv2D(f2, (3,3), activation='relu',  padding='same')(r14)\n",
    "    r14 = tf.keras.layers.add([r14,c14])\n",
    "    r14 = tf.keras.layers.Conv2D(f2, (3,3), activation='relu',  padding='same')(r14)\n",
    "\n",
    "    u15 = tf.keras.layers.Conv2DTranspose(f1, (2,2), activation='relu', strides = (2,2), padding = 'same')(r14)\n",
    "    u15 = tf.keras.layers.concatenate([u15, r1])\n",
    "    u15 = tf.keras.layers.BatchNormalization()(u15)\n",
    "\n",
    "    c15 = tf.keras.layers.Conv2D(f1, (3,3), activation='relu',  padding='same')(u15)\n",
    "    d15 = tf.keras.layers.Dropout(Dropout)(c15)\n",
    "    r15 = tf.keras.layers.Conv2D(f1, (3,3), activation='relu',  padding='same')(d15)\n",
    "    r15 = tf.keras.layers.Conv2D(f1, (3,3), activation='relu',  padding='same')(r15)\n",
    "    r15 = tf.keras.layers.add([r15,c15])\n",
    "    r15 = tf.keras.layers.Conv2D(f1, (3,3), activation='relu',  padding='same')(r15)\n",
    "\n",
    "    c16 = tf.keras.layers.Conv2D(f1, (3,3), activation='relu',  padding='same')(r15)\n",
    "    c16 = tf.keras.layers.BatchNormalization()(c16)\n",
    "\n",
    "    outputs = tf.keras.layers.Conv2D(1, (1,1), activation='sigmoid')(c16)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "    \n",
    "# ICH and SAH models.\n",
    "model.compile(optimizer='adam', loss = dice_loss, metrics=[dice_coeff])\n",
    "\n",
    "# IVH model\n",
    "# model.compile(optimizer='adam', loss = combined_loss, metrics=[dice_coeff]) # For IVH model training\n",
    "model.summary()\n",
    "\n",
    "model_name = 'ICH' # one of 'ICH','IVH','SAH'\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath= model_name + '.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af27c181",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "masks = []\n",
    "\n",
    "patients = os.listdir('data/')\n",
    "print(len(patients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eeb8b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(patients)):\n",
    "    image = nib.load('data/'+patients[i]+'/'+patients[i].split('.')[0]+'.nii')\n",
    "    image = np.array(image.dataobj).astype(np.float32)\n",
    "    image = np.rollaxis(image,2,0)\n",
    "    image = np.expand_dims(image,3)\n",
    "    empty = []\n",
    "    if image[0].shape == (512,512,1):\n",
    "        images.append(image)\n",
    "    else:\n",
    "        print('RESIZING')\n",
    "        for a in range(len(image)):\n",
    "            x = image[a,:,:,0].astype(np.float32)\n",
    "            x = cv2.resize(x,(512,512))\n",
    "            x = np.expand_dims(x,2)\n",
    "            empty.append(np.expand_dims(x,0))\n",
    "        image = np.concatenate(empty)\n",
    "        print(image.shape)\n",
    "        images.append(image)\n",
    "            \n",
    "    seg = nib.load('data/'+patients[i]+'/segmentation.nii')\n",
    "    seg = np.array(seg.dataobj).astype(np.bool_)\n",
    "    seg = np.rollaxis(seg,2,0)\n",
    "    seg = np.expand_dims(seg,3)\n",
    "    empty = []\n",
    "    if seg[0].shape == (512,512,1):\n",
    "        masks.append(seg)\n",
    "    else:\n",
    "        print('RESIZING')\n",
    "        for a in range(len(seg)):\n",
    "            x = seg[a,:,:,0].astype(np.float32)\n",
    "            x = cv2.resize(x,(512,512))\n",
    "            x = np.expand_dims(x,2)\n",
    "            empty.append(np.expand_dims(x,0))\n",
    "        seg = np.concatenate(empty).astype(np.bool_)\n",
    "        print(seg.shape)\n",
    "        masks.append(seg)     \n",
    "    print(patients[i],' done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcebb824",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.concatenate(images)\n",
    "y = np.concatenate(masks)\n",
    "\n",
    "# for ICH and SAH models\n",
    "x = normalize(x)\n",
    "\n",
    "# for IVH model\n",
    "# x = normalize2(x)\n",
    "\n",
    "print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b0db3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "masks = []\n",
    "\n",
    "for i in range(len(x)):\n",
    "    image = np.expand_dims(x[i],0)\n",
    "    images.append(image)\n",
    "    image = np.rot90(image,1,(1,2))\n",
    "    images.append(image)\n",
    "    image = np.rot90(image,1,(1,2))\n",
    "    images.append(image)\n",
    "    image = np.rot90(image,1,(1,2))\n",
    "    images.append(image)\n",
    "    mask = np.expand_dims(y[i],0)\n",
    "    masks.append(mask)\n",
    "    mask = np.rot90(mask,1,(1,2))\n",
    "    masks.append(mask)\n",
    "    mask = np.rot90(mask,1,(1,2))\n",
    "    masks.append(mask)\n",
    "    mask = np.rot90(mask,1,(1,2))\n",
    "    masks.append(mask)\n",
    "\n",
    "print(len(images),len(masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d172a8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.concatenate(images)\n",
    "y = np.concatenate(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7dd698",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x,y,batch_size=32,epochs=200,validation_split=0.2,callbacks=[checkpoint])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
